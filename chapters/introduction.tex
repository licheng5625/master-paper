\chapter{Introduction} % (fold)
\label{cha:introduction}
Twitter is a mircoblogging service which are used by millions users. Users can publish and exchange information with short tweets within 140 characters. It is cheap and can be accessed though several like website, email or mobile phone. That makes it a ideal media for spreading breaking news and false rumors.  A study by the Pew Research Center showed that the people in USA under age of 30 consider Internet as the major resource of news and Internet became the second important media overall \cite{kohut2008internet}.

But these advantages make Twitter which became one of the most importance resources of breaking news, at the same time becomes into a ideal media for spreading unverified information. On Twitter everyone can be a journalist and publish news or rumors without any substantiation which must be done by traditional journalists before news' publishing. 

 Rumor could be defined as a statement whose truth value is unverified or deliberately false \cite{qazvinian2011rumor}. And they could be harmful to the government, market and society. One case is some hacked accounts spread a rumor about Obama had been injured in white house. The S\&P crashed and wiped off 130 Billion dollars of stock value \cite{matthews2013does}. 
 
 So a method of detecting rumors on Twitter that could detect rumors in the early stage of propagation can be very useful.    
 The structure is shown in figure \ref{fig:pipeline}. First 1) we crawled the data from Twitter interface, 2) we use beautiful soup and spark technologies to extract feature from the tweets, 3) we extract time series features and fit to the dynamic series-time structure 4) we use the text of tweets as feature to train the single tweet's credibility scoring model neural network and merge the its output to the time series features, 5) training the time series model with DSTS.  
 
 \begin{figure}[!h]
\centering
\includegraphics[width=0.7\columnwidth]{images/structuremodel.png}
\caption{ pipeline of the rumor detecting system }
\label{fig:pipeline}
\end{figure}

 \newpage
 \subsection{Contributions}
In this thesis, we make the following contributions:

\begin{itemize}
	
	\item We develop a model of classification of single tweet with high credibility or low credibility. We call it \textsc{single tweet's creditability scoring model}. Considering it could be set up online for the early rumor events detection in the further and it should response as quick as possible. So we use only the features which can be extracted from one tweet in the Twitter's interface. We test 2 models. One is random decision forest with handcrafted features. Because the features are limited, it gets only 64\% accuracy. Second model what we tested is based on zhou's\cite{zhou2015c} work, it is a hybrid CNN and LSTM model for text classification. The result of this model we called it credit score with 81\% accuracy.

 	\item We develop a time series model for detecting rumor events. We used Dynamic Series-Time Structure (DSTS)\cite{liu2015real} to capture the changes of features over time. And we tested 3 time series model as feature: modified Spike Model \cite{kwon2013prominent}, SIS model and SEIZ model\cite{jin2013epidemiological}. We add the results of credit scoring model as a feature into time series model to improve the performance in the early stage. And we approved that credit score is one of the best feature in the rumor detection task. In 48 hours after the event's spreading we got 90\% accuracy to detect the rumor events. 

 	\item We study how features changes over time during the spreading of rumors.

 \end{itemize}
 
 
\subsection{Thesis Outline}

(xiugai)
The rest of this these is organized as follows: In Chapter~\ref{cha:researcher_engagement_with_web_archives} we try to understand the research practices of humanities scholars when working with web archives. We also seek to find problems faced by the scholars when accessing web archives using keyword search. Based on our findings we introduce Historical Query Intents(HQIs) in Chapter~\ref{cha:historical_search}. In the same chapter we also motivate and develop a novel retrieval model suited for HQIs. The experiments to test the performance of this model against its competitors is covered in the same chapter. The penultimate Chapter~\ref{cha:the_historical_search_system} details the architecture of the system that was built to demonstrate the efficacy of the retrieval models to users. Finally, in Chapter~\ref{cha:conclusion_and_future_work} we add some concluding remarks and describe future work.

% chapter introduction (end)